{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4b5528",
   "metadata": {},
   "source": [
    "# NLP for Movie Plots\n",
    "*Hongyuan Jin, Eunseo Kang, Paige Harris, and Viki Papadakis*\n",
    "\n",
    "## Purpose\n",
    "We use natural language processing tools to find similar movies based on their summary plots.\n",
    "\n",
    "## Methodology\n",
    "- TF-IDF\n",
    "- LDA\n",
    "\n",
    "## WIP - improvements\n",
    "Todos:\n",
    "- replace character names with 'character'\n",
    "- verify the clustering efficiency\n",
    "-\n",
    "\n",
    "## Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "## Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9b94b",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import for Python\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b533b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  /Users/aj/PycharmProjects/film_python\n"
     ]
    },
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "# print(\"Current Working Directory \" , os.getcwd())\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Visualizations\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as ply\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(theme='white')\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Autoreload extension\n",
    "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "    \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Library import for R\n",
    "We enable R in the notebook and import all the required libraries."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/bin/macosx/contrib/4.0/lmtest_0.9-38.tgz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 399050 bytes (389 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 389 KB\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/_5/gg08zw2j57j_yx44r4y359p00000gn/T//Rtmpb1Q609/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# install.packages(\"ggplot2\", repos='http://cran.us.r-project.org', quiet=TRUE)\n",
    "library(ggplot2)\n",
    "library(fixest)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(tidyverse)\n",
    "# install.packages(\"lmtest\")\n",
    "library(lmtest)\n",
    "library(sandwich)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "b200c9f6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Local library import\n",
    "We import all the required local libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3340985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include local library paths\n",
    "import sys\n",
    "# sys.path.append('path/to/local/lib') # uncomment and fill to import local libraries\n",
    "\n",
    "# Import local libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2f6e8",
   "metadata": {},
   "source": [
    "# Data import\n",
    "We first retrieve the data for movie summary plots.\n",
    "*Source:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "  Release Year                             Title Origin/Ethnicity  \\\n0         1901            Kansas Saloon Smashers         American   \n1         1901     Love by the Light of the Moon         American   \n2         1901           The Martyred Presidents         American   \n3         1901  Terrible Teddy, the Grizzly King         American   \n4         1902            Jack and the Beanstalk         American   \n\n                             Director Cast    Genre  \\\n0                             Unknown  NaN  unknown   \n1                             Unknown  NaN  unknown   \n2                             Unknown  NaN  unknown   \n3                             Unknown  NaN  unknown   \n4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n\n                                           Wiki Page  \\\n0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n\n                                                Plot Unnamed: 8  \n0  A bartender is working at a saloon, serving dr...        NaN  \n1  The moon, painted with a smiling face hangs ov...        NaN  \n2  The film, just over a minute long, is composed...        NaN  \n3  Lasting just 61 seconds and consisting of two ...        NaN  \n4  The earliest known adaptation of the classic f...        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Release Year</th>\n      <th>Title</th>\n      <th>Origin/Ethnicity</th>\n      <th>Director</th>\n      <th>Cast</th>\n      <th>Genre</th>\n      <th>Wiki Page</th>\n      <th>Plot</th>\n      <th>Unnamed: 8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1901</td>\n      <td>Kansas Saloon Smashers</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n      <td>A bartender is working at a saloon, serving dr...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1901</td>\n      <td>Love by the Light of the Moon</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n      <td>The moon, painted with a smiling face hangs ov...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1901</td>\n      <td>The Martyred Presidents</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n      <td>The film, just over a minute long, is composed...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1901</td>\n      <td>Terrible Teddy, the Grizzly King</td>\n      <td>American</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n      <td>Lasting just 61 seconds and consisting of two ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1902</td>\n      <td>Jack and the Beanstalk</td>\n      <td>American</td>\n      <td>George S. Fleming, Edwin S. Porter</td>\n      <td>NaN</td>\n      <td>unknown</td>\n      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n      <td>The earliest known adaptation of the classic f...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('~/Dropbox/Course/PSTAT234/spr21/pstat234-final-project/wiki_movie_plots_deduped.csv')\n",
    "movies_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We subset the data for movies produced in the US and reindex the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "movies_df_sub = movies_df[(movies_df['Origin/Ethnicity']==\"American\")].reset_index(drop=True)\n",
    "# movies_df_sub = movies_df[(movies_df['Release Year']=='2000')\n",
    "#                           & (movies_df['Origin/Ethnicity']==\"American\")].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "cccaef3e",
   "metadata": {},
   "source": [
    "# Data processing for movie plots"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP\n",
    "We use TF-IDF and LDA for our plot summary analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cf8f7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17377, 78)\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=False)\n",
    "\n",
    "normalized = []\n",
    "totalvocab_tokenized = []\n",
    "def normalize(X):\n",
    "    normalized = []\n",
    "    # totalvocab_tokenized = []\n",
    "    for x in X:\n",
    "        words = nltk.word_tokenize(x)\n",
    "        normalized.append(' '.join([stemmer.stem(word) for word in words if re.match('[a-zA-Z]+', word)]))\n",
    "        totalvocab_tokenized.extend(words)\n",
    "    return normalized\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('normalize', FunctionTransformer(normalize, validate=False)),\n",
    "    ('counter_vectorizer', CountVectorizer(\n",
    "        max_df=0.8, max_features=200000,\n",
    "        min_df=0.2, stop_words='english',\n",
    "        ngram_range=(1, 3)\n",
    "    )),\n",
    "    ('tfidf_transform', TfidfTransformer())\n",
    "])\n",
    "\n",
    "tfidf_matrix = pipe.fit_transform([x for x in movies_df_sub['Plot']])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "similarity_distance = 1 - cosine_similarity(tfidf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We test for finding similar movies for a given title"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def find_similar(title):\n",
    "    index = movies_df_sub[movies_df_sub['Title'] == title].index[0]\n",
    "    vector = similarity_distance[index, :]\n",
    "    most_similar = movies_df_sub.iloc[np.argsort(vector)[0:10], 0:2]\n",
    "    return most_similar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The movies similar to *Madagascar (2005)* according to TF-IDF."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Release Year                       Title\n",
      "14711         2005                  Madagascar\n",
      "13292         1998                  The Mighty\n",
      "12531         1995  The Pebble and the Penguin\n",
      "13112         1997             Robinson Crusoe\n",
      "14944         2006                  Happy Feet\n",
      "10331         1985                      Brazil\n",
      "17171         2017  xXx: Return of Xander Cage\n",
      "14384         2003                  Wrong Turn\n",
      "10034         1982                        Tron\n",
      "12924         1997         Beverly Hills Ninja\n"
     ]
    }
   ],
   "source": [
    "print(find_similar('Madagascar'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualize the movies within a certain similarity range\n",
    "TBU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cluster the movies based on the similarity metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 23\n",
    "# print(num_clusters)\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters_tfidf = km.labels_.tolist()\n",
    "\n",
    "import joblib\n",
    "\n",
    "#uncomment the below to save your model\n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km, 'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "films = {'title': movies_df_sub[\"Title\"], 'Release_year':  movies_df_sub[\"Release Year\"],\n",
    "         'Plot':  movies_df_sub['Plot'], 'cluster': clusters_tfidf,\n",
    "         'Director':  movies_df_sub['Director'], 'Genre':  movies_df_sub['Genre']}\n",
    "# print(films)\n",
    "frame = pd.DataFrame(data=films, columns=['title', 'cluster', 'Genre', 'Release_year', 'Director'])\n",
    "# print(frame)\n",
    "print(frame['cluster'].value_counts())\n",
    "# frame.to_csv(r'~/Dropbox/ImmInnHollywood/data/wiki_film_plot/plot_cluster.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LDA\n",
    "\n",
    "TBU-Text explanation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 appear\n",
      "1 assault\n",
      "2 bartend\n",
      "3 beer\n",
      "4 begin\n",
      "5 break\n",
      "6 bucket\n",
      "7 burst\n",
      "8 cash\n",
      "9 charact\n",
      "10 custom\n",
      "11 drink\n",
      "12 dump\n",
      "13 everybodi\n",
      "14 eye\n",
      "15 face\n",
      "[(0, 0.13227954703913156),\n",
      " (1, 0.3790397673199794),\n",
      " (2, 0.374438855287237),\n",
      " (3, 0.2172397731360707),\n",
      " (4, 0.15173497760613988),\n",
      " (5, 0.1399498994366303),\n",
      " (6, 0.14142404420842042),\n",
      " (7, 0.14506212816523342),\n",
      " (8, 0.1793527179919929),\n",
      " (9, 0.13013718763569648),\n",
      " (10, 0.1350117256373554),\n",
      " (11, 0.3686891209949009),\n",
      " (12, 0.16259719029079714),\n",
      " (13, 0.26063277479936975),\n",
      " (14, 0.18848108896763566),\n",
      " (15, 0.20067540564150227),\n",
      " (16, 0.17125349985356006),\n",
      " (17, 0.1172126069805695),\n",
      " (18, 0.15900581156216126),\n",
      " (19, 0.19577237362575506),\n",
      " (20, 0.22411229640680644),\n",
      " (21, 0.10452823017669358),\n",
      " (22, 0.1628664933090168)]\n",
      "Topic: 0 \n",
      "Words: 0.014*\"alic\" + 0.006*\"shaw\" + 0.003*\"doyl\" + 0.003*\"mitch\" + 0.003*\"gang\" + 0.002*\"kid\" + 0.002*\"door\" + 0.002*\"suzi\" + 0.002*\"parent\" + 0.002*\"ellen\"\n",
      "Topic: 1 \n",
      "Words: 0.007*\"band\" + 0.006*\"ethan\" + 0.005*\"logan\" + 0.004*\"nora\" + 0.004*\"lili\" + 0.003*\"music\" + 0.003*\"debbi\" + 0.003*\"spike\" + 0.003*\"fletcher\" + 0.002*\"record\"\n",
      "Topic: 2 \n",
      "Words: 0.010*\"charli\" + 0.004*\"king\" + 0.004*\"team\" + 0.003*\"crew\" + 0.003*\"agent\" + 0.003*\"nicki\" + 0.003*\"andi\" + 0.002*\"compani\" + 0.002*\"teddi\" + 0.002*\"race\"\n",
      "Topic: 3 \n",
      "Words: 0.016*\"nick\" + 0.004*\"rick\" + 0.004*\"franki\" + 0.003*\"ethan\" + 0.003*\"babi\" + 0.003*\"miller\" + 0.002*\"campbel\" + 0.002*\"student\" + 0.002*\"wyatt\" + 0.002*\"rocki\"\n",
      "Topic: 4 \n",
      "Words: 0.006*\"game\" + 0.006*\"team\" + 0.003*\"babi\" + 0.003*\"mike\" + 0.003*\"player\" + 0.002*\"child\" + 0.002*\"parent\" + 0.002*\"danc\" + 0.002*\"colleg\" + 0.002*\"crash\"\n",
      "Topic: 5 \n",
      "Words: 0.005*\"jeff\" + 0.004*\"book\" + 0.004*\"woodi\" + 0.004*\"harri\" + 0.003*\"magic\" + 0.003*\"camp\" + 0.003*\"malcolm\" + 0.003*\"daisi\" + 0.003*\"gang\" + 0.002*\"parent\"\n",
      "Topic: 6 \n",
      "Words: 0.007*\"greg\" + 0.006*\"bug\" + 0.005*\"jeff\" + 0.003*\"water\" + 0.002*\"bird\" + 0.002*\"door\" + 0.002*\"tucker\" + 0.002*\"killer\" + 0.002*\"babi\" + 0.002*\"restaur\"\n",
      "Topic: 7 \n",
      "Words: 0.004*\"turtl\" + 0.003*\"parent\" + 0.003*\"maddi\" + 0.003*\"collin\" + 0.003*\"clair\" + 0.002*\"jane\" + 0.002*\"whitey\" + 0.002*\"dori\" + 0.002*\"agent\" + 0.002*\"king\"\n",
      "Topic: 8 \n",
      "Words: 0.009*\"matt\" + 0.005*\"harri\" + 0.005*\"mike\" + 0.003*\"boy\" + 0.003*\"jona\" + 0.003*\"game\" + 0.003*\"ella\" + 0.003*\"team\" + 0.002*\"indian\" + 0.002*\"armi\"\n",
      "Topic: 9 \n",
      "Words: 0.008*\"ship\" + 0.007*\"chris\" + 0.006*\"team\" + 0.006*\"crew\" + 0.005*\"harri\" + 0.004*\"earth\" + 0.004*\"shark\" + 0.003*\"power\" + 0.003*\"human\" + 0.003*\"robot\"\n",
      "Topic: 10 \n",
      "Words: 0.004*\"chris\" + 0.004*\"white\" + 0.003*\"buddi\" + 0.003*\"fred\" + 0.003*\"kiss\" + 0.003*\"christma\" + 0.003*\"black\" + 0.003*\"beast\" + 0.003*\"date\" + 0.003*\"hotel\"\n",
      "Topic: 11 \n",
      "Words: 0.007*\"doug\" + 0.004*\"dusti\" + 0.003*\"silver\" + 0.003*\"anim\" + 0.003*\"luci\" + 0.002*\"freddi\" + 0.002*\"bean\" + 0.002*\"gang\" + 0.002*\"richi\" + 0.002*\"killer\"\n",
      "Topic: 12 \n",
      "Words: 0.005*\"maggi\" + 0.005*\"jake\" + 0.004*\"zombi\" + 0.004*\"race\" + 0.004*\"hunter\" + 0.003*\"duke\" + 0.003*\"phil\" + 0.003*\"batman\" + 0.003*\"dori\" + 0.003*\"captain\"\n",
      "Topic: 13 \n",
      "Words: 0.009*\"grace\" + 0.004*\"zach\" + 0.004*\"taylor\" + 0.003*\"jeff\" + 0.003*\"hotel\" + 0.003*\"darci\" + 0.003*\"judith\" + 0.002*\"parent\" + 0.002*\"door\" + 0.002*\"write\"\n",
      "Topic: 14 \n",
      "Words: 0.005*\"harri\" + 0.004*\"owen\" + 0.003*\"paint\" + 0.003*\"connor\" + 0.002*\"drug\" + 0.002*\"case\" + 0.002*\"suicid\" + 0.002*\"wolf\" + 0.002*\"jade\" + 0.002*\"hugh\"\n",
      "Topic: 15 \n",
      "Words: 0.010*\"jane\" + 0.008*\"emma\" + 0.006*\"mike\" + 0.005*\"simon\" + 0.005*\"drug\" + 0.003*\"howard\" + 0.002*\"coupl\" + 0.002*\"wed\" + 0.002*\"human\" + 0.002*\"doctor\"\n",
      "Topic: 16 \n",
      "Words: 0.007*\"pete\" + 0.005*\"marti\" + 0.005*\"island\" + 0.005*\"abbi\" + 0.005*\"carter\" + 0.004*\"joan\" + 0.004*\"ship\" + 0.004*\"boat\" + 0.003*\"mason\" + 0.003*\"dorothi\"\n",
      "Topic: 17 \n",
      "Words: 0.003*\"agent\" + 0.003*\"bomb\" + 0.003*\"plane\" + 0.003*\"mission\" + 0.003*\"alli\" + 0.003*\"pete\" + 0.002*\"presid\" + 0.002*\"battl\" + 0.002*\"soldier\" + 0.002*\"pilot\"\n",
      "Topic: 18 \n",
      "Words: 0.006*\"dave\" + 0.005*\"alien\" + 0.005*\"ship\" + 0.004*\"jake\" + 0.004*\"chuck\" + 0.004*\"monster\" + 0.003*\"elli\" + 0.003*\"luci\" + 0.003*\"power\" + 0.003*\"island\"\n",
      "Topic: 19 \n",
      "Words: 0.009*\"dylan\" + 0.008*\"ghost\" + 0.006*\"mike\" + 0.006*\"snow\" + 0.005*\"clair\" + 0.005*\"alien\" + 0.004*\"jess\" + 0.003*\"queen\" + 0.003*\"priest\" + 0.003*\"littl\"\n",
      "Topic: 20 \n",
      "Words: 0.008*\"sophi\" + 0.005*\"oliv\" + 0.004*\"elliot\" + 0.003*\"edith\" + 0.003*\"ranger\" + 0.003*\"cole\" + 0.003*\"race\" + 0.003*\"team\" + 0.003*\"bear\" + 0.003*\"wallac\"\n",
      "Topic: 21 \n",
      "Words: 0.006*\"helen\" + 0.004*\"clark\" + 0.003*\"superman\" + 0.003*\"ship\" + 0.003*\"salli\" + 0.003*\"compani\" + 0.002*\"team\" + 0.002*\"parent\" + 0.002*\"hank\" + 0.002*\"crew\"\n",
      "Topic: 22 \n",
      "Words: 0.002*\"phone\" + 0.002*\"jacki\" + 0.002*\"hotel\" + 0.002*\"experi\" + 0.002*\"vampir\" + 0.002*\"power\" + 0.002*\"team\" + 0.002*\"case\" + 0.002*\"suicid\" + 0.002*\"agent\"\n",
      "Topic: 0 Word: 0.005*\"luci\" + 0.005*\"maya\" + 0.004*\"violet\" + 0.004*\"creatur\" + 0.004*\"manni\" + 0.003*\"beatric\" + 0.003*\"beast\" + 0.003*\"vampir\" + 0.002*\"team\" + 0.002*\"alien\"\n",
      "Topic: 1 Word: 0.005*\"lincoln\" + 0.003*\"daisi\" + 0.003*\"satellit\" + 0.003*\"schmidt\" + 0.003*\"cassi\" + 0.003*\"drug\" + 0.002*\"fang\" + 0.002*\"fiona\" + 0.002*\"benji\" + 0.002*\"ape\"\n",
      "Topic: 2 Word: 0.013*\"nick\" + 0.005*\"emma\" + 0.004*\"kenni\" + 0.003*\"lara\" + 0.003*\"loop\" + 0.003*\"prom\" + 0.003*\"conni\" + 0.002*\"hartman\" + 0.002*\"wade\" + 0.002*\"hobb\"\n",
      "Topic: 3 Word: 0.003*\"chris\" + 0.002*\"charli\" + 0.002*\"jeff\" + 0.002*\"alic\" + 0.002*\"drug\" + 0.002*\"charley\" + 0.002*\"vicki\" + 0.002*\"teddi\" + 0.001*\"team\" + 0.001*\"mike\"\n",
      "Topic: 4 Word: 0.006*\"dylan\" + 0.003*\"robot\" + 0.003*\"sawyer\" + 0.003*\"chris\" + 0.003*\"sandi\" + 0.003*\"fred\" + 0.003*\"planet\" + 0.003*\"darci\" + 0.002*\"superman\" + 0.002*\"fletcher\"\n",
      "Topic: 5 Word: 0.004*\"pope\" + 0.003*\"buddi\" + 0.003*\"matt\" + 0.003*\"zombi\" + 0.003*\"josh\" + 0.003*\"holm\" + 0.002*\"harri\" + 0.002*\"frost\" + 0.002*\"fawcett\" + 0.002*\"utah\"\n",
      "Topic: 6 Word: 0.010*\"maddi\" + 0.006*\"sophia\" + 0.006*\"sadi\" + 0.006*\"vinni\" + 0.005*\"elsa\" + 0.005*\"griffin\" + 0.005*\"caleb\" + 0.004*\"camper\" + 0.004*\"lizzi\" + 0.004*\"franki\"\n",
      "Topic: 7 Word: 0.013*\"jake\" + 0.003*\"isabel\" + 0.003*\"turtl\" + 0.003*\"gardner\" + 0.002*\"wyatt\" + 0.002*\"nick\" + 0.002*\"bishop\" + 0.002*\"agatha\" + 0.002*\"alien\" + 0.002*\"superhero\"\n",
      "Topic: 8 Word: 0.003*\"jacki\" + 0.003*\"bella\" + 0.002*\"freddi\" + 0.002*\"team\" + 0.002*\"pete\" + 0.002*\"laurel\" + 0.002*\"greg\" + 0.002*\"charli\" + 0.002*\"mickey\" + 0.002*\"duke\"\n",
      "Topic: 9 Word: 0.010*\"malcolm\" + 0.007*\"elli\" + 0.006*\"chester\" + 0.005*\"israel\" + 0.004*\"hobb\" + 0.004*\"hacker\" + 0.004*\"paulin\" + 0.003*\"center\" + 0.003*\"team\" + 0.003*\"car\"\n",
      "Topic: 10 Word: 0.004*\"carter\" + 0.004*\"owen\" + 0.004*\"woodi\" + 0.003*\"virus\" + 0.002*\"taggart\" + 0.002*\"celest\" + 0.002*\"chuck\" + 0.002*\"compani\" + 0.002*\"agent\" + 0.002*\"motel\"\n",
      "Topic: 11 Word: 0.004*\"donni\" + 0.003*\"roman\" + 0.003*\"edith\" + 0.003*\"penni\" + 0.003*\"snow\" + 0.002*\"lenni\" + 0.002*\"hank\" + 0.002*\"mirror\" + 0.002*\"alma\" + 0.002*\"charli\"\n",
      "Topic: 12 Word: 0.004*\"terrorist\" + 0.004*\"zeus\" + 0.004*\"portal\" + 0.003*\"eden\" + 0.003*\"hercul\" + 0.003*\"seal\" + 0.003*\"holt\" + 0.002*\"wand\" + 0.002*\"mose\" + 0.002*\"zach\"\n",
      "Topic: 13 Word: 0.010*\"cartel\" + 0.009*\"logan\" + 0.008*\"penguin\" + 0.005*\"mitch\" + 0.004*\"irv\" + 0.003*\"hatti\" + 0.003*\"marijuana\" + 0.002*\"tornado\" + 0.002*\"mildr\" + 0.002*\"nick\"\n",
      "Topic: 14 Word: 0.003*\"grace\" + 0.003*\"witch\" + 0.002*\"demon\" + 0.002*\"christma\" + 0.002*\"spirit\" + 0.002*\"parent\" + 0.002*\"child\" + 0.002*\"josh\" + 0.002*\"stark\" + 0.002*\"dwight\"\n",
      "Topic: 15 Word: 0.002*\"vampir\" + 0.002*\"human\" + 0.002*\"infect\" + 0.001*\"nicki\" + 0.001*\"rudi\" + 0.001*\"dean\" + 0.001*\"drug\" + 0.001*\"soldier\" + 0.001*\"compani\" + 0.001*\"cooper\"\n",
      "Topic: 16 Word: 0.004*\"sonni\" + 0.004*\"nate\" + 0.004*\"theo\" + 0.003*\"louie\" + 0.003*\"logan\" + 0.003*\"whitey\" + 0.003*\"josh\" + 0.003*\"julian\" + 0.003*\"sydney\" + 0.003*\"franco\"\n",
      "Topic: 17 Word: 0.007*\"berni\" + 0.006*\"richi\" + 0.004*\"archi\" + 0.004*\"tanner\" + 0.004*\"missi\" + 0.003*\"nixon\" + 0.003*\"dragon\" + 0.003*\"jeff\" + 0.003*\"warhead\" + 0.002*\"augustus\"\n",
      "Topic: 18 Word: 0.009*\"abbi\" + 0.007*\"zombi\" + 0.004*\"nigel\" + 0.004*\"xavier\" + 0.003*\"shaw\" + 0.003*\"juliett\" + 0.003*\"hoover\" + 0.003*\"judd\" + 0.003*\"kris\" + 0.003*\"matti\"\n",
      "Topic: 19 Word: 0.010*\"sophi\" + 0.007*\"ethan\" + 0.007*\"matt\" + 0.007*\"doug\" + 0.005*\"vinc\" + 0.004*\"dusti\" + 0.003*\"judith\" + 0.003*\"milli\" + 0.003*\"oliv\" + 0.002*\"merced\"\n",
      "Topic: 20 Word: 0.004*\"alien\" + 0.004*\"video\" + 0.003*\"noah\" + 0.003*\"batman\" + 0.002*\"tobi\" + 0.002*\"earth\" + 0.002*\"ship\" + 0.002*\"mike\" + 0.002*\"crew\" + 0.002*\"ramsey\"\n",
      "Topic: 21 Word: 0.007*\"elliot\" + 0.006*\"chloe\" + 0.005*\"jonah\" + 0.004*\"milo\" + 0.003*\"hansen\" + 0.003*\"chris\" + 0.003*\"phil\" + 0.003*\"cult\" + 0.003*\"santiago\" + 0.002*\"island\"\n",
      "Topic: 22 Word: 0.005*\"harri\" + 0.004*\"paint\" + 0.004*\"dracula\" + 0.003*\"matt\" + 0.003*\"lena\" + 0.002*\"olymp\" + 0.002*\"shaw\" + 0.002*\"sebastian\" + 0.002*\"game\" + 0.002*\"team\"\n",
      "\n",
      "Score: 0.9690808653831482\t \n",
      "Topic: 0.003*\"chris\" + 0.002*\"charli\" + 0.002*\"jeff\" + 0.002*\"alic\" + 0.002*\"drug\" + 0.002*\"charley\" + 0.002*\"vicki\" + 0.002*\"teddi\" + 0.001*\"team\" + 0.001*\"mike\"\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "processed_docs = movies_df_sub['Plot'].map(preprocess)\n",
    "processed_docs[:10]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 15:\n",
    "        break\n",
    "\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.1, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=23, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=23, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "\n",
    "mdiff, annotation = lda_model_tfidf.diff(lda_model_tfidf)\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import data for names and replace the character names with string 'character'\n",
    "\n",
    "We find that the topic modeling is affected by the character names.\n",
    "Below we will replace the names with the 'Character'\n",
    "\n",
    "*Data source:*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name gender  count\n",
      "19456          Zoe      M      5\n",
      "11575      Natacia      F      5\n",
      "11574      Nasreen      F      5\n",
      "11573     Nashanda      F      5\n",
      "11572       Narine      F      5\n",
      "...            ...    ...    ...\n",
      "12165        David      M  41920\n",
      "12164        Jason      M  48170\n",
      "12163  Christopher      M  49096\n",
      "0         Jennifer      F  58379\n",
      "12162      Michael      M  68704\n",
      "\n",
      "[19457 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = '~/Dropbox/Course/PSTAT234/spr21/pstat234-final-project/yob1980.txt'\n",
    "names = pd.read_csv(filename, delimiter = \",\", header=None)\n",
    "names.columns = [\"name\", 'gender', 'count']\n",
    "names.head(5)\n",
    "names = names.sort_values('count')\n",
    "# keep the names with more than 1000 counts\n",
    "# names = names[names['count']>=100]\n",
    "print(names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = names.name.tolist()\n",
    "# print(name)\n",
    "'Alice' in name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "# load names.zip which has more names data txt files\n",
    "import zipfile\n",
    "with zipfile.ZipFile('/Users/aj/Dropbox/Course/PSTAT234/spr21/pstat234-final-project/names.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('names/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "data": {
      "text/plain": "(2020863, 3)"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "allnames_files = Path('names').glob('yob*')\n",
    "# print(allnames_files)\n",
    "# allnames_files.sort()\n",
    "allnames_list = list()\n",
    "\n",
    "for f in allnames_files:\n",
    "    step_1 = pd.read_csv(f, delimiter = ',', header=None)\n",
    "    allnames_list.append(step_1)\n",
    "allnames = pd.concat(allnames_list)\n",
    "allnames.columns = [\"name\", 'gender', 'count']\n",
    "allnames.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "data": {
      "text/plain": "           name  count\n1076   Jacqueli    157\n1099   Cassandr    152\n14787  Christop   1082",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1076</th>\n      <td>Jacqueli</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <th>1099</th>\n      <td>Cassandr</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>14787</th>\n      <td>Christop</td>\n      <td>1082</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allnames.dtypes\n",
    "## drop gender and aggregate the counts groupby names\n",
    "# allnames.drop(['gender'], axis = 1, inplace = True)\\\n",
    "#     .groupby('name').agg({'count': 'sum'})\n",
    "# allnames.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "data": {
      "text/plain": "(375, 3)"
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates and keep only the names with count larger than 100\n",
    "allnames.drop_duplicates(subset='name',\n",
    "                         keep = False, inplace= True)\n",
    "allnames = allnames[allnames['count']>=10]\n",
    "allnames.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "replace every name in the plot with character\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-233-69bae71a3a30>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mtag\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mmovies_df_sub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPlot\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr'\\b'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtag\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34mr'\\b'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Character'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmovies_df_sub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPlot\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmovies_df_sub\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPlot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;31m# Plot.to_csv('test.csv', index=False)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "# # ALERT: THIS CELL TAKES VERY LONG TO RUN\n",
    "# # The name is a list from the names data of yob1980.txt\n",
    "# for i in movies_df_sub.index:\n",
    "#     for tag in name:\n",
    "#         movies_df_sub.Plot[i] = re.sub(r'\\b' + tag + r'\\b', 'Character', movies_df_sub.Plot[i])\n",
    "#\n",
    "# # Plot.to_csv('test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "# ALERT: THIS CELL TAKES EVEN LONGER TO RUN\n",
    "# The name is a list from the all names data\n",
    "name = allnames.name.to_list()\n",
    "for i in movies_df_sub.index:\n",
    "    for tag in name:\n",
    "        movies_df_sub.Plot[i] = re.sub(r'\\b' + tag + r'\\b', 'Character', movies_df_sub.Plot[i])\n",
    "\n",
    "# Plot.to_csv('test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF with the updated plot summaries\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tfidf_matrix = pipe.fit_transform([x for x in movies_df_sub['Plot']])\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 23\n",
    "# print(num_clusters)\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters_tfidf = km.labels_.tolist()\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(km, 'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "films = {'title': movies_df_sub[\"Title\"], 'Release_year':  movies_df_sub[\"Release Year\"],\n",
    "         'Plot':  movies_df_sub['Plot'], 'cluster': clusters_tfidf,\n",
    "         'Director':  movies_df_sub['Director'], 'Genre':  movies_df_sub['Genre']}\n",
    "# print(films)\n",
    "frame = pd.DataFrame(data=films, columns=['title', 'cluster', 'Genre', 'Release_year', 'Director'])\n",
    "# print(frame)\n",
    "print(frame['cluster'].value_counts())\n",
    "# frame.to_csv(r'~/Dropbox/ImmInnHollywood/data/wiki_film_plot/plot_cluster.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LDA with the updated plot summaries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_docs = movies_df_sub['Plot'].map(preprocess)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 15:\n",
    "        break\n",
    "\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.1, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break\n",
    "\n",
    "# lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=23, id2word=dictionary, passes=2, workers=4)\n",
    "# for idx, topic in lda_model.print_topics(-1):\n",
    "#     print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=23, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "\n",
    "mdiff, annotation = lda_model_tfidf.diff(lda_model_tfidf)\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize the plot text (word cloud)\n",
    "\n",
    "- Overall topic\n",
    "- US-born director\n",
    "- Foreign-born director\n",
    "- Genre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the data with other movie attributes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "                      Name          Dirct1          Prodc1  \\\n0         300 Year Weekend  Victor Stoloff             NaN   \n1  A Bullet For Pretty Boy  Larry Buchanan  Larry Buchanan   \n2       A Day at the Beach    Simon Hesera  Roman Polanski   \n3      A Man Called Sledge      Vic Morrow     Harry Bloom   \n4      A Run For the Money   Robert Canton   Robert Canton   \n\n                      Distributor Cinematographer1         Actor1  \\\n0  Cinerama Releasing Corporation      Joseph Brun  Michael Tolan   \n1                             NaN              NaN         Fabian   \n2              Paramount Pictures   Gilbert Taylor     Mark Burns   \n3                   Sony Pictures  Luigi Kuveiller   James Garner   \n4                             NaN   Ken Van Sickle    Fred Dennis   \n\n            Actor2         Actor3          Actor4           Actor5   Genre  \\\n0  Sharon Laughlin     Roy Cooper    Gabriel Dell        M'el Dowd   Drama   \n1     Jocelyn Lane  Astrid Warner  Michael Haynes      Adam Roarke  Action   \n2   Beatrice Edney  Peter Sellers             NaN              NaN   Drama   \n3    Dennis Weaver   Claude Akins     John Marley  Laura Antonelli  Action   \n4         Kim Pope     Bob Walden      Lisa Emmet     Eileen Dietz   Crime   \n\n   us.year  us.quarter  domestic_bo  internaional_bo  budget_nielsen  \\\n0     1970         NaN          NaN              NaN             NaN   \n1     1970         NaN          NaN              NaN             NaN   \n2     1970         NaN          NaN              NaN             NaN   \n3     1970         NaN          NaN              NaN             NaN   \n4     1970         NaN          NaN              NaN             NaN   \n\n   budget_numbers  director_imm director_continent director_country  \\\n0             NaN  Foreign-born                NaN         Russian    \n1             NaN           NaN                NaN              NaN   \n2             NaN           NaN                NaN              NaN   \n3             NaN           NaN                NaN              NaN   \n4             NaN           NaN                NaN              NaN   \n\n  director_gender director_race  international_bo  \n0             NaN           NaN               NaN  \n1             NaN           NaN               NaN  \n2             NaN           NaN               NaN  \n3             NaN           NaN               NaN  \n4             NaN           NaN               NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Dirct1</th>\n      <th>Prodc1</th>\n      <th>Distributor</th>\n      <th>Cinematographer1</th>\n      <th>Actor1</th>\n      <th>Actor2</th>\n      <th>Actor3</th>\n      <th>Actor4</th>\n      <th>Actor5</th>\n      <th>Genre</th>\n      <th>us.year</th>\n      <th>us.quarter</th>\n      <th>domestic_bo</th>\n      <th>internaional_bo</th>\n      <th>budget_nielsen</th>\n      <th>budget_numbers</th>\n      <th>director_imm</th>\n      <th>director_continent</th>\n      <th>director_country</th>\n      <th>director_gender</th>\n      <th>director_race</th>\n      <th>international_bo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300 Year Weekend</td>\n      <td>Victor Stoloff</td>\n      <td>NaN</td>\n      <td>Cinerama Releasing Corporation</td>\n      <td>Joseph Brun</td>\n      <td>Michael Tolan</td>\n      <td>Sharon Laughlin</td>\n      <td>Roy Cooper</td>\n      <td>Gabriel Dell</td>\n      <td>M'el Dowd</td>\n      <td>Drama</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Foreign-born</td>\n      <td>NaN</td>\n      <td>Russian</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A Bullet For Pretty Boy</td>\n      <td>Larry Buchanan</td>\n      <td>Larry Buchanan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fabian</td>\n      <td>Jocelyn Lane</td>\n      <td>Astrid Warner</td>\n      <td>Michael Haynes</td>\n      <td>Adam Roarke</td>\n      <td>Action</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day at the Beach</td>\n      <td>Simon Hesera</td>\n      <td>Roman Polanski</td>\n      <td>Paramount Pictures</td>\n      <td>Gilbert Taylor</td>\n      <td>Mark Burns</td>\n      <td>Beatrice Edney</td>\n      <td>Peter Sellers</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Drama</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Man Called Sledge</td>\n      <td>Vic Morrow</td>\n      <td>Harry Bloom</td>\n      <td>Sony Pictures</td>\n      <td>Luigi Kuveiller</td>\n      <td>James Garner</td>\n      <td>Dennis Weaver</td>\n      <td>Claude Akins</td>\n      <td>John Marley</td>\n      <td>Laura Antonelli</td>\n      <td>Action</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A Run For the Money</td>\n      <td>Robert Canton</td>\n      <td>Robert Canton</td>\n      <td>NaN</td>\n      <td>Ken Van Sickle</td>\n      <td>Fred Dennis</td>\n      <td>Kim Pope</td>\n      <td>Bob Walden</td>\n      <td>Lisa Emmet</td>\n      <td>Eileen Dietz</td>\n      <td>Crime</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_other = pd.read_csv('~/Dropbox/Course/PSTAT234/spr21/pstat234-final-project/df_pstat234.csv')\n",
    "movies_other.head(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the data with big star names\n",
    "*Source: https://www.imdb.com/list/ls058011111/?sort=list_order,asc&mode=detail*\n",
    "*Scraped, code attached separately*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Name\n0      Robert De Niro\n1      Jack Nicholson\n2       Marlon Brando\n3   Denzel Washington\n4   Katharine Hepburn",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Robert De Niro</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jack Nicholson</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Marlon Brando</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Denzel Washington</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Katharine Hepburn</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topstar = pd.read_csv('~/Dropbox/Course/PSTAT234/spr21/pstat234-final-project/topstar.csv')\n",
    "topstar.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## merge the data frames\n",
    "- other movie attributes (*movies_other*)\n",
    "- plot clustering with updated plots (*frame*)\n",
    "- top star indicator (*topstar*)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "data": {
      "text/plain": "                      Name           Dirct1          Prodc1  \\\n0         300 Year Weekend   Victor Stoloff             NaN   \n1  A Bullet For Pretty Boy   Larry Buchanan  Larry Buchanan   \n2       A Day at the Beach     Simon Hesera  Roman Polanski   \n3      A Man Called Sledge       Vic Morrow     Harry Bloom   \n4      A Run For the Money    Robert Canton   Robert Canton   \n5      A.K.A. Cassius Clay       Jim Jacobs  William Cayton   \n6      About Me: A Musical     Robert Frank             NaN   \n7           Adam at 6 A.M.  Robert Scheerer  Rick Rosenberg   \n8                  Airport    George Seaton     Ross Hunter   \n9       Alex in Wonderland    Paul Mazursky    Larry Tucker   \n\n                      Distributor    Cinematographer1             Actor1  \\\n0  Cinerama Releasing Corporation         Joseph Brun      Michael Tolan   \n1                             NaN                 NaN             Fabian   \n2              Paramount Pictures      Gilbert Taylor         Mark Burns   \n3                   Sony Pictures     Luigi Kuveiller       James Garner   \n4                             NaN      Ken Van Sickle        Fred Dennis   \n5                             NaN   Isidore Mankofsky                NaN   \n6                             NaN                 NaN                NaN   \n7       National General Pictures  Charles Rosher Jr.    Michael Douglas   \n8                       Universal       Ernest Laszlo     Burt Lancaster   \n9                             NaN       Laszlo Kovacs  Donald Sutherland   \n\n            Actor2         Actor3              Actor4           Actor5  \\\n0  Sharon Laughlin     Roy Cooper        Gabriel Dell        M'el Dowd   \n1     Jocelyn Lane  Astrid Warner      Michael Haynes      Adam Roarke   \n2   Beatrice Edney  Peter Sellers                 NaN              NaN   \n3    Dennis Weaver   Claude Akins         John Marley  Laura Antonelli   \n4         Kim Pope     Bob Walden          Lisa Emmet     Eileen Dietz   \n5              NaN            NaN                 NaN              NaN   \n6              NaN            NaN                 NaN              NaN   \n7      Lee Purcell  Joe Don Baker        Grayson Hall   Charles Aidman   \n8      Dean Martin    Jean Seberg  Jacqueline Bisset)   George Kennedy   \n9    Ellen Burstyn   Meg Mazursky      Glenna Sergent     Viola Spolin   \n\n          Genre  us.year  us.quarter  domestic_bo  internaional_bo  \\\n0         Drama     1970         NaN          NaN              NaN   \n1        Action     1970         NaN          NaN              NaN   \n2         Drama     1970         NaN          NaN              NaN   \n3        Action     1970         NaN          NaN              NaN   \n4         Crime     1970         NaN          NaN              NaN   \n5   Documentary     1970         NaN          NaN              NaN   \n6  Experimental     1971         NaN          NaN              NaN   \n7         Drama     1970         NaN          NaN              NaN   \n8      Thriller     1970         NaN          NaN              NaN   \n9        Comedy     1970         NaN          NaN              NaN   \n\n   budget_nielsen  budget_numbers  director_imm  director_continent  \\\n0             NaN             NaN  Foreign-born                 NaN   \n1             NaN             NaN           NaN                 NaN   \n2             NaN             NaN           NaN                 NaN   \n3             NaN             NaN           NaN                 NaN   \n4             NaN             NaN           NaN                 NaN   \n5             NaN             NaN           NaN                 NaN   \n6             NaN             NaN   Native-born  North America (US)   \n7             NaN             NaN           NaN                 NaN   \n8      10000000.0             NaN   Native-born  North America (US)   \n9             NaN             NaN   Native-born  North America (US)   \n\n  director_country director_gender director_race  international_bo  \n0         Russian              NaN           NaN               NaN  \n1              NaN             NaN           NaN               NaN  \n2              NaN             NaN           NaN               NaN  \n3              NaN             NaN           NaN               NaN  \n4              NaN             NaN           NaN               NaN  \n5              NaN             NaN           NaN               NaN  \n6               US             NaN           NaN               NaN  \n7              NaN             NaN           NaN               NaN  \n8               US             NaN           NaN               NaN  \n9               US             NaN           NaN               NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Dirct1</th>\n      <th>Prodc1</th>\n      <th>Distributor</th>\n      <th>Cinematographer1</th>\n      <th>Actor1</th>\n      <th>Actor2</th>\n      <th>Actor3</th>\n      <th>Actor4</th>\n      <th>Actor5</th>\n      <th>Genre</th>\n      <th>us.year</th>\n      <th>us.quarter</th>\n      <th>domestic_bo</th>\n      <th>internaional_bo</th>\n      <th>budget_nielsen</th>\n      <th>budget_numbers</th>\n      <th>director_imm</th>\n      <th>director_continent</th>\n      <th>director_country</th>\n      <th>director_gender</th>\n      <th>director_race</th>\n      <th>international_bo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300 Year Weekend</td>\n      <td>Victor Stoloff</td>\n      <td>NaN</td>\n      <td>Cinerama Releasing Corporation</td>\n      <td>Joseph Brun</td>\n      <td>Michael Tolan</td>\n      <td>Sharon Laughlin</td>\n      <td>Roy Cooper</td>\n      <td>Gabriel Dell</td>\n      <td>M'el Dowd</td>\n      <td>Drama</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Foreign-born</td>\n      <td>NaN</td>\n      <td>Russian</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A Bullet For Pretty Boy</td>\n      <td>Larry Buchanan</td>\n      <td>Larry Buchanan</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fabian</td>\n      <td>Jocelyn Lane</td>\n      <td>Astrid Warner</td>\n      <td>Michael Haynes</td>\n      <td>Adam Roarke</td>\n      <td>Action</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A Day at the Beach</td>\n      <td>Simon Hesera</td>\n      <td>Roman Polanski</td>\n      <td>Paramount Pictures</td>\n      <td>Gilbert Taylor</td>\n      <td>Mark Burns</td>\n      <td>Beatrice Edney</td>\n      <td>Peter Sellers</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Drama</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A Man Called Sledge</td>\n      <td>Vic Morrow</td>\n      <td>Harry Bloom</td>\n      <td>Sony Pictures</td>\n      <td>Luigi Kuveiller</td>\n      <td>James Garner</td>\n      <td>Dennis Weaver</td>\n      <td>Claude Akins</td>\n      <td>John Marley</td>\n      <td>Laura Antonelli</td>\n      <td>Action</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A Run For the Money</td>\n      <td>Robert Canton</td>\n      <td>Robert Canton</td>\n      <td>NaN</td>\n      <td>Ken Van Sickle</td>\n      <td>Fred Dennis</td>\n      <td>Kim Pope</td>\n      <td>Bob Walden</td>\n      <td>Lisa Emmet</td>\n      <td>Eileen Dietz</td>\n      <td>Crime</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A.K.A. Cassius Clay</td>\n      <td>Jim Jacobs</td>\n      <td>William Cayton</td>\n      <td>NaN</td>\n      <td>Isidore Mankofsky</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Documentary</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>About Me: A Musical</td>\n      <td>Robert Frank</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Experimental</td>\n      <td>1971</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Native-born</td>\n      <td>North America (US)</td>\n      <td>US</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Adam at 6 A.M.</td>\n      <td>Robert Scheerer</td>\n      <td>Rick Rosenberg</td>\n      <td>National General Pictures</td>\n      <td>Charles Rosher Jr.</td>\n      <td>Michael Douglas</td>\n      <td>Lee Purcell</td>\n      <td>Joe Don Baker</td>\n      <td>Grayson Hall</td>\n      <td>Charles Aidman</td>\n      <td>Drama</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Airport</td>\n      <td>George Seaton</td>\n      <td>Ross Hunter</td>\n      <td>Universal</td>\n      <td>Ernest Laszlo</td>\n      <td>Burt Lancaster</td>\n      <td>Dean Martin</td>\n      <td>Jean Seberg</td>\n      <td>Jacqueline Bisset)</td>\n      <td>George Kennedy</td>\n      <td>Thriller</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10000000.0</td>\n      <td>NaN</td>\n      <td>Native-born</td>\n      <td>North America (US)</td>\n      <td>US</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Alex in Wonderland</td>\n      <td>Paul Mazursky</td>\n      <td>Larry Tucker</td>\n      <td>NaN</td>\n      <td>Laszlo Kovacs</td>\n      <td>Donald Sutherland</td>\n      <td>Ellen Burstyn</td>\n      <td>Meg Mazursky</td>\n      <td>Glenna Sergent</td>\n      <td>Viola Spolin</td>\n      <td>Comedy</td>\n      <td>1970</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Native-born</td>\n      <td>North America (US)</td>\n      <td>US</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "generate top star indicator for each movie if one of the main actors is on the list of top star from the above source."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name         Dirct1 Prodc1                    Distributor\n",
      "1 300 Year Weekend Victor Stoloff   <NA> Cinerama Releasing Corporation\n",
      "  Cinematographer1        Actor1          Actor2     Actor3       Actor4\n",
      "1      Joseph Brun Michael Tolan Sharon Laughlin Roy Cooper Gabriel Dell\n",
      "     Actor5 Genre us.year us.quarter domestic_bo internaional_bo budget_nielsen\n",
      "1 M'el Dowd Drama    1970         NA          NA              NA             NA\n",
      "  budget_numbers director_imm director_continent director_country\n",
      "1             NA Foreign-born               <NA>         Russian \n",
      "  director_gender director_race international_bo\n",
      "1            <NA>          <NA>               NA\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "movies_other = read.csv('~/Dropbox/Course/PSTAT234/spr21/pstat234-final-project/df_pstat234.csv')\n",
    "movies_other[1, ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "TBU\n",
    "\n",
    "*with figures and summary statistics*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f261e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# -i df -w 5 -h 5 --units in -r 200\n",
    "# import df from global environment\n",
    "# make default figure size 5 by 5 inches with 200 dpi resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression analysis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: NOTE: 21,559 observations removed because of NA values (LHS: 15,404, RHS: 21,248, Fixed-effects: 7,917).\n",
      "\n",
      "R[write to console]: Warning:\n",
      "R[write to console]:  In print.fixest(object, useS4 = FALSE):\n",
      " 'useS4' is not a valid argument of function print.fixest (fyi, some of\n",
      "its main arguments are 'n', 'type', 'se' and 'cluster').\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS estimation, Dep. Var.: log(domestic_bo + sqrt(1 + domestic_bo^2))\n",
      "Observations: 3,319 \n",
      "Fixed-effects: us.year: 40,  Genre: 21,  Distributor: 268\n",
      "Standard-errors: Clustered (us.year) \n",
      "                        Estimate Std. Error   t value    Pr(>|t|)    \n",
      "director_immNative-born 0.329304   0.067021  4.913500 1.60000e-05 ***\n",
      "director_genderMale     0.000707   0.142389  0.004966 9.96063e-01    \n",
      "log(1 + budget_nielsen) 0.700227   0.052000 13.466000 3.02000e-16 ***\n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "Log-likelihood: -5,967.91   Adj. R2: 0.64172 \n",
      "                          R2-Within: 0.16848 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "fit1 = feols(log(domestic_bo + sqrt(1+domestic_bo^2)) ~ director_imm + director_gender + log(1+budget_nielsen)  | us.year + Genre + Distributor, data =movies_other)\n",
    "summary(fit1)\n",
    "\n",
    "# fit2 = feols(log(international_bo + sqrt(1+international_bo^2)) ~ director_imm + log(1+budget_numbers) | us.year + Genre + Distributor, movies_other)\n",
    "# summary(fit2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: NOTE: 21,330 observations removed because of NA values (LHS: 15,404, RHS: 20,927, Fixed-effects: 7,917).\n",
      "\n",
      "R[write to console]: Warning:\n",
      "R[write to console]:  In print.fixest(object, useS4 = FALSE):\n",
      " 'useS4' is not a valid argument of function print.fixest (fyi, some of\n",
      "its main arguments are 'n', 'type', 'se' and 'cluster').\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS estimation, Dep. Var.: log(domestic_bo + sqrt(1 + domestic_bo^2))\n",
      "Observations: 3,548 \n",
      "Fixed-effects: us.year: 40,  Genre: 21,  Distributor: 315\n",
      "Standard-errors: Clustered (us.year) \n",
      "                        Estimate Std. Error   t value    Pr(>|t|)    \n",
      "log(1 + budget_nielsen) 0.676808   0.050244 13.471000 2.98000e-16 ***\n",
      "director_genderMale     0.016215   0.134817  0.120277 9.04881e-01    \n",
      "---\n",
      "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "Log-likelihood: -6,415.09   Adj. R2: 0.66227 \n",
      "                          R2-Within: 0.16042 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "fit11st = feols(log(domestic_bo + sqrt(1+domestic_bo^2)) ~ log(1+budget_nielsen) + director_gender | us.year + Genre + Distributor, data =movies_other)\n",
    "summary(fit11st)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "lm(formula = resid(fit11st) ~ director_imm, data = movies_other)\n",
      "\n",
      "Residuals:\n",
      "    Min      1Q  Median      3Q     Max \n",
      "-9.2280 -0.5893  0.1672  0.8513  6.3669 \n",
      "\n",
      "Coefficients:\n",
      "                        Estimate Std. Error t value Pr(>|t|)    \n",
      "(Intercept)             -0.16719    0.04340  -3.853 0.000119 ***\n",
      "director_immNative-born  0.27472    0.05363   5.122 3.19e-07 ***\n",
      "---\n",
      "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n",
      "\n",
      "Residual standard error: 1.469 on 3317 degrees of freedom\n",
      "  (21559 observations deleted due to missingness)\n",
      "Multiple R-squared:  0.007848,\tAdjusted R-squared:  0.007548 \n",
      "F-statistic: 26.24 on 1 and 3317 DF,  p-value: 3.193e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "fit11 = lm(resid(fit11st) ~ director_imm, movies_other)\n",
    "summary(fit11)\n",
    "# fit11cl = coeftest(fit11, vcov. = vcovCL, cluster = ~cluster)\n",
    "# fit11cl\n",
    "\n",
    "# fit21st = feols(log(intNationbo_numbers + sqrt(1+intNationbo_numbers^2)) ~ log(1+budget_numbers)| us.year + Genre.Recode + Distributor, df)\n",
    "# summary(fit21st)\n",
    "# fit22 = lm(resid(fit21st) ~ dir1.imm, df)\n",
    "# fit22cl = coeftest(fit22, vcov. = vcovCL, cluster = ~cluster)\n",
    "# fit22cl\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "We report here relevant references:\n",
    "1. author1, article1, journal1, year1, url1\n",
    "2. author2, article2, journal2, year2, url2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Appendix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "example showing how the preprocessing works"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the Central Park Zoo, Marty the zebra is celebrating his tenth birthday, but has grown bored with his daily routine and longs to experience the wild. Marty's best friend is Alex the lion, who enjoys showing off for the public and his celebrity status as \"the King of New York City\". Alex attempts to cheer Marty up, but Marty, still unsatisfied, gets some tips from the zoo's penguinsSkipper, Kowalski, Rico, and Privatewho are trying to escape the zoo, and follows them out. Alex, Melman the giraffe, and Gloria the hippopotamus pursue Marty in an attempt to convince him to return. The four, along with the penguins and two chimpanzees named Mason and Phil, find themselves at Grand Central Station, where they are quickly sedated via tranquillizer gun when Alex's attempt to communicate with humans is mistaken for aggression. The zoo, under pressure from anti-captivity activists, is forced to ship the escaped animals by sea to a Kenyan wildlife preserve. During their travels, the penguins escape from their enclosure and take over the ship, intent on taking it to Antarctica. Their antics on the bridge cause the crates containing Alex, Marty, Melman, and Gloria to fall overboard and wash ashore on Madagascar, because the strap securing the crates broke off due to Alex and Marty fighting.\r\n",
      "The animals are soon able to regroup, initially believing themselves to be at the San Diego Zoo. Upon exploring, however, they come across a pack of lemurs, led by King Julien XIII the ring-tailed lemur, and learn their true location. Alex blames Marty for their predicament and attempts to signal for help to get back to civilization. Marty, on the other hand, finds the wild to be exactly what he was looking for, with Gloria and Melman soon joining him in enjoying the island. Alex eventually comes around, but, deprived from the raw steaks he was provided with at the zoo, his prey drive begins to show as hunger kicks in. The group is accepted by the lemurs, though King Julien's adviser, Maurice the aye-aye, cautions them about Alex's predatory nature. King Julien ignores Maurice's concerns and persuades the group to help the lemurs fend off the fossa, who hunt the lemurs as prey. While Alex initially scares the fossa away and is worshiped by the lemurs, later, compelled by hunger, he attacks Marty. Realizing that Alex is now a threat, King Julien banishes him to the far side of the island where the fossa live. Seeing what has happened to Alex, and how difficult it is to survive with so many predators around the island, Marty begins to regret his decision to leave the zoo.\r\n",
      "The penguins, having been to Antarctica and found that it wasn't what they had in mind, land the ship at Madagascar. Seeing this as a chance to return Alex to New York, Marty rushes after his friend against the wishes of Melman and Gloria. Marty attempts to convince the now grizzled, starving Alex to return, but Alex refuses out of fear of attacking Marty again. The penguins, Gloria, and Melman go to find Marty, but are trapped by the fossa. At the last minute, Alex overcomes his predatory instincts and scares the fossa away from the lemur territory forever. The lemurs regain their respect for Alex, and the penguins help him satisfy his hunger through sushi. As the lemurs throw a farewell celebration for the foursome, the penguins decide not to break the news that the ship has run out of fuel.\n",
      "original document: \n",
      "['At', 'the', 'Central', 'Park', 'Zoo,', 'Marty', 'the', 'zebra', 'is', 'celebrating', 'his', 'tenth', 'birthday,', 'but', 'has', 'grown', 'bored', 'with', 'his', 'daily', 'routine', 'and', 'longs', 'to', 'experience', 'the', 'wild.', \"Marty's\", 'best', 'friend', 'is', 'Alex', 'the', 'lion,', 'who', 'enjoys', 'showing', 'off', 'for', 'the', 'public', 'and', 'his', 'celebrity', 'status', 'as', '\"the', 'King', 'of', 'New', 'York', 'City\".', 'Alex', 'attempts', 'to', 'cheer', 'Marty', 'up,', 'but', 'Marty,', 'still', 'unsatisfied,', 'gets', 'some', 'tips', 'from', 'the', \"zoo's\", 'penguinsSkipper,', 'Kowalski,', 'Rico,', 'and', 'Privatewho', 'are', 'trying', 'to', 'escape', 'the', 'zoo,', 'and', 'follows', 'them', 'out.', 'Alex,', 'Melman', 'the', 'giraffe,', 'and', 'Gloria', 'the', 'hippopotamus', 'pursue', 'Marty', 'in', 'an', 'attempt', 'to', 'convince', 'him', 'to', 'return.', 'The', 'four,', 'along', 'with', 'the', 'penguins', 'and', 'two', 'chimpanzees', 'named', 'Mason', 'and', 'Phil,', 'find', 'themselves', 'at', 'Grand', 'Central', 'Station,', 'where', 'they', 'are', 'quickly', 'sedated', 'via', 'tranquillizer', 'gun', 'when', \"Alex's\", 'attempt', 'to', 'communicate', 'with', 'humans', 'is', 'mistaken', 'for', 'aggression.', 'The', 'zoo,', 'under', 'pressure', 'from', 'anti-captivity', 'activists,', 'is', 'forced', 'to', 'ship', 'the', 'escaped', 'animals', 'by', 'sea', 'to', 'a', 'Kenyan', 'wildlife', 'preserve.', 'During', 'their', 'travels,', 'the', 'penguins', 'escape', 'from', 'their', 'enclosure', 'and', 'take', 'over', 'the', 'ship,', 'intent', 'on', 'taking', 'it', 'to', 'Antarctica.', 'Their', 'antics', 'on', 'the', 'bridge', 'cause', 'the', 'crates', 'containing', 'Alex,', 'Marty,', 'Melman,', 'and', 'Gloria', 'to', 'fall', 'overboard', 'and', 'wash', 'ashore', 'on', 'Madagascar,', 'because', 'the', 'strap', 'securing', 'the', 'crates', 'broke', 'off', 'due', 'to', 'Alex', 'and', 'Marty', 'fighting.\\r\\nThe', 'animals', 'are', 'soon', 'able', 'to', 'regroup,', 'initially', 'believing', 'themselves', 'to', 'be', 'at', 'the', 'San', 'Diego', 'Zoo.', 'Upon', 'exploring,', 'however,', 'they', 'come', 'across', 'a', 'pack', 'of', 'lemurs,', 'led', 'by', 'King', 'Julien', 'XIII', 'the', 'ring-tailed', 'lemur,', 'and', 'learn', 'their', 'true', 'location.', 'Alex', 'blames', 'Marty', 'for', 'their', 'predicament', 'and', 'attempts', 'to', 'signal', 'for', 'help', 'to', 'get', 'back', 'to', 'civilization.', 'Marty,', 'on', 'the', 'other', 'hand,', 'finds', 'the', 'wild', 'to', 'be', 'exactly', 'what', 'he', 'was', 'looking', 'for,', 'with', 'Gloria', 'and', 'Melman', 'soon', 'joining', 'him', 'in', 'enjoying', 'the', 'island.', 'Alex', 'eventually', 'comes', 'around,', 'but,', 'deprived', 'from', 'the', 'raw', 'steaks', 'he', 'was', 'provided', 'with', 'at', 'the', 'zoo,', 'his', 'prey', 'drive', 'begins', 'to', 'show', 'as', 'hunger', 'kicks', 'in.', 'The', 'group', 'is', 'accepted', 'by', 'the', 'lemurs,', 'though', 'King', \"Julien's\", 'adviser,', 'Maurice', 'the', 'aye-aye,', 'cautions', 'them', 'about', \"Alex's\", 'predatory', 'nature.', 'King', 'Julien', 'ignores', \"Maurice's\", 'concerns', 'and', 'persuades', 'the', 'group', 'to', 'help', 'the', 'lemurs', 'fend', 'off', 'the', 'fossa,', 'who', 'hunt', 'the', 'lemurs', 'as', 'prey.', 'While', 'Alex', 'initially', 'scares', 'the', 'fossa', 'away', 'and', 'is', 'worshiped', 'by', 'the', 'lemurs,', 'later,', 'compelled', 'by', 'hunger,', 'he', 'attacks', 'Marty.', 'Realizing', 'that', 'Alex', 'is', 'now', 'a', 'threat,', 'King', 'Julien', 'banishes', 'him', 'to', 'the', 'far', 'side', 'of', 'the', 'island', 'where', 'the', 'fossa', 'live.', 'Seeing', 'what', 'has', 'happened', 'to', 'Alex,', 'and', 'how', 'difficult', 'it', 'is', 'to', 'survive', 'with', 'so', 'many', 'predators', 'around', 'the', 'island,', 'Marty', 'begins', 'to', 'regret', 'his', 'decision', 'to', 'leave', 'the', 'zoo.\\r\\nThe', 'penguins,', 'having', 'been', 'to', 'Antarctica', 'and', 'found', 'that', 'it', \"wasn't\", 'what', 'they', 'had', 'in', 'mind,', 'land', 'the', 'ship', 'at', 'Madagascar.', 'Seeing', 'this', 'as', 'a', 'chance', 'to', 'return', 'Alex', 'to', 'New', 'York,', 'Marty', 'rushes', 'after', 'his', 'friend', 'against', 'the', 'wishes', 'of', 'Melman', 'and', 'Gloria.', 'Marty', 'attempts', 'to', 'convince', 'the', 'now', 'grizzled,', 'starving', 'Alex', 'to', 'return,', 'but', 'Alex', 'refuses', 'out', 'of', 'fear', 'of', 'attacking', 'Marty', 'again.', 'The', 'penguins,', 'Gloria,', 'and', 'Melman', 'go', 'to', 'find', 'Marty,', 'but', 'are', 'trapped', 'by', 'the', 'fossa.', 'At', 'the', 'last', 'minute,', 'Alex', 'overcomes', 'his', 'predatory', 'instincts', 'and', 'scares', 'the', 'fossa', 'away', 'from', 'the', 'lemur', 'territory', 'forever.', 'The', 'lemurs', 'regain', 'their', 'respect', 'for', 'Alex,', 'and', 'the', 'penguins', 'help', 'him', 'satisfy', 'his', 'hunger', 'through', 'sushi.', 'As', 'the', 'lemurs', 'throw', 'a', 'farewell', 'celebration', 'for', 'the', 'foursome,', 'the', 'penguins', 'decide', 'not', 'to', 'break', 'the', 'news', 'that', 'the', 'ship', 'has', 'run', 'out', 'of', 'fuel.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['central', 'park', 'marti', 'zebra', 'celebr', 'tenth', 'birthday', 'grow', 'bore', 'daili', 'routin', 'long', 'experi', 'wild', 'marti', 'best', 'friend', 'alex', 'lion', 'enjoy', 'show', 'public', 'celebr', 'status', 'king', 'york', 'citi', 'alex', 'attempt', 'cheer', 'marti', 'marti', 'unsatisfi', 'get', 'tip', 'penguin', 'skipper', 'kowalski', 'rico', 'privat', 'tri', 'escap', 'follow', 'alex', 'melman', 'giraff', 'gloria', 'hippopotamus', 'pursu', 'marti', 'attempt', 'convinc', 'return', 'penguin', 'chimpanze', 'name', 'mason', 'phil', 'grand', 'central', 'station', 'quick', 'sedat', 'tranquil', 'alex', 'attempt', 'communic', 'human', 'mistak', 'aggress', 'pressur', 'anti', 'captiv', 'activist', 'forc', 'ship', 'escap', 'anim', 'kenyan', 'wildlif', 'preserv', 'travel', 'penguin', 'escap', 'enclosur', 'ship', 'intent', 'take', 'antarctica', 'antic', 'bridg', 'caus', 'crate', 'contain', 'alex', 'marti', 'melman', 'gloria', 'fall', 'overboard', 'wash', 'ashor', 'madagascar', 'strap', 'secur', 'crate', 'break', 'alex', 'marti', 'fight', 'anim', 'soon', 'abl', 'regroup', 'initi', 'believ', 'diego', 'explor', 'come', 'pack', 'lemur', 'king', 'julien', 'xiii', 'ring', 'tail', 'lemur', 'learn', 'true', 'locat', 'alex', 'blame', 'marti', 'predica', 'attempt', 'signal', 'help', 'civil', 'marti', 'hand', 'find', 'wild', 'exact', 'look', 'gloria', 'melman', 'soon', 'join', 'enjoy', 'island', 'alex', 'eventu', 'come', 'depriv', 'steak', 'provid', 'prey', 'drive', 'begin', 'hunger', 'kick', 'group', 'accept', 'lemur', 'king', 'julien', 'advis', 'mauric', 'caution', 'alex', 'predatori', 'natur', 'king', 'julien', 'ignor', 'mauric', 'concern', 'persuad', 'group', 'help', 'lemur', 'fend', 'fossa', 'hunt', 'lemur', 'prey', 'alex', 'initi', 'scar', 'fossa', 'away', 'worship', 'lemur', 'later', 'compel', 'hunger', 'attack', 'marti', 'realiz', 'alex', 'threat', 'king', 'julien', 'banish', 'island', 'fossa', 'live', 'see', 'happen', 'alex', 'difficult', 'surviv', 'predat', 'island', 'marti', 'begin', 'regret', 'decis', 'leav', 'penguin', 'have', 'antarctica', 'wasn', 'mind', 'land', 'ship', 'madagascar', 'see', 'chanc', 'return', 'alex', 'york', 'marti', 'rush', 'friend', 'wish', 'melman', 'gloria', 'marti', 'attempt', 'convinc', 'grizzl', 'starv', 'alex', 'return', 'alex', 'refus', 'fear', 'attack', 'marti', 'penguin', 'gloria', 'melman', 'marti', 'trap', 'fossa', 'minut', 'alex', 'overcom', 'predatori', 'instinct', 'scar', 'fossa', 'away', 'lemur', 'territori', 'forev', 'lemur', 'regain', 'respect', 'alex', 'penguin', 'help', 'satisfi', 'hunger', 'sushi', 'lemur', 'throw', 'farewel', 'celebr', 'foursom', 'penguin', 'decid', 'break', 'news', 'ship', 'fuel']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = movies_df_sub[movies_df_sub['Title'] == 'Madagascar'].values[0][7]\n",
    "print(doc_sample)\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "testing with name replacement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "miniplot = movies_df_sub.Plot[5]\n",
    "# miniplot.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(miniplot)\n",
    "# tags = ['Alice', 'John']\n",
    "for tag in names:\n",
    "    miniplot = miniplot.replace(tag, 'Character')\n",
    "\n",
    "print(miniplot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for tag in name:\n",
    "    miniplot = re.sub(r'\\b' + tag + r'\\b', 'Character', miniplot)\n",
    "print(miniplot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Plot = movies_df_sub.Plot.sample(10)\n",
    "for i in Plot.index:\n",
    "    for tag in name:\n",
    "        Plot[i] = re.sub(r'\\b' + tag + r'\\b', 'Character', Plot[i])\n",
    "print(Plot)\n",
    "# Plot.to_csv('test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'Grace' in name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}